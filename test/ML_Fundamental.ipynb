{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e0d2b86-2eb0-43cb-9aea-187609beeffb",
   "metadata": {},
   "source": [
    "### 인공지능 > 머신러닝 > 딥러닝\n",
    "- 머신러닝 : 프로그램과 데이터로 스스로 학습을 통해서 (예측/ 분류/ 군집)하는 모델을 생성하는 알고리즘\n",
    "- 딥러닝 : 머신러닝의 일부, neural network를 사용해서 학습하는 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc72eee-1bb0-4e0a-a842-0f7a69956a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5820723-6c89-4737-a646-73b7ec6adf8f",
   "metadata": {},
   "source": [
    "### 머신러닝\n",
    "- 지도학습 : 어떤 것을 예측하거나 분류하는 알고리즘(회귀, 분류)\n",
    "- 비지도 학습: 예측대상이 없는 경우(군집분석)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9be34e-e888-41fc-bec3-7210b19e146d",
   "metadata": {},
   "source": [
    "### 회귀분석 : 연속값을 예측하는 알고리즘\n",
    "- 내년도에 매출을 예상해서 매출에 맞춰서 재고 미리 주문\n",
    "- 기업실적을 기반으로 기업의 주가를 예측, 앞으로 오를 주식을 미리 산다\n",
    "- 당료병수치, 앞으로 미래의 당수치를 예상하고 예방한다.\n",
    "- 학습시간, 선행학습, 운동, 건강, 미래의 성적을 예측\n",
    "- 경제성장률 예측, 기업에서 내년도 성장률에 따라서 회사 매출성장을 예상, 비용절감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf668e0-a151-4618-8483-ccb1c68a7169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20b3e9fb-a32a-409d-bf78-cf97f4825231",
   "metadata": {},
   "source": [
    "### 분류분석 \n",
    "- 이혼률예측, 어떤 신혼부부가 행복하게 살자, 이혼할지\n",
    "- 질병을 미리 예측, 특정 질병에 걸릴 확률을 미리 예상\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47152b61-a5e7-4bc7-ad48-89d68994ee08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1c7ae20-1981-4738-b7f6-ac9cbe08c5a3",
   "metadata": {},
   "source": [
    "### 머신러닝 학습 순서\n",
    "1. 데이터 확보\n",
    "2. 데이터 전처리(preprocessing, data cleaning) - null처리, datatype 숫자로 바꾸기, 이상치제거, 정규화\n",
    "3. EDA - 데이터분석(시각화, 통계, DataAnalysis)\n",
    "4. target data 정의/ target data와 input data를 분리\n",
    "5. train data, test data 분리\n",
    "6. train data는 알고리즘을 학습 시 사용/ test data는 학습 후 생성된 모델의 성능을 평가에 사용\n",
    "7. 학습시킬 알고리즘을 import\n",
    "8. 알고리즘에 데이터를 제공해서 학습을 진행, 알고리즘이 데이터를 기반으로 스스로 학습함.\n",
    "9. 예측 모델의 성능을 평가 - 모델이 예측한 값과 실제값이 얼마나 잘 맞는지 확인\\\n",
    "        => pred = algo.predict(X_test)\n",
    "        => pred(모델이 예측한 값) vs 실제값이 얼마나 잘 맞는지 확인\n",
    "        => MSE, RMSE, MAE, F2 score로 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a057886-a747-4603-a6bd-6f3094be671a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37e336df-18da-4f14-91d4-8c02537eda8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinearRegression1 복습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bc45155-07db-44d0-9cce-3e2274f9949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 집값을 예측하는 모델을 생성\n",
    "#단독주택의 시세를 정확하게 계산/예측하는 모델을 생성\n",
    "# 집값: target => y\n",
    "# 입력데이터 : 동네소득수준, 집의 면수, 방의 갯수, 침실의 수, 지역 인구수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02c8eb3a-d830-4ace-9eaf-22717b7f219f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg. Area Income</th>\n",
       "      <th>Avg. Area House Age</th>\n",
       "      <th>Avg. Area Number of Rooms</th>\n",
       "      <th>Avg. Area Number of Bedrooms</th>\n",
       "      <th>Area Population</th>\n",
       "      <th>Price</th>\n",
       "      <th>Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79545.458574</td>\n",
       "      <td>5.682861</td>\n",
       "      <td>7.009188</td>\n",
       "      <td>4.09</td>\n",
       "      <td>23086.800503</td>\n",
       "      <td>1.059034e+06</td>\n",
       "      <td>208 Michael Ferry Apt. 674\\nLaurabury, NE 3701...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79248.642455</td>\n",
       "      <td>6.002900</td>\n",
       "      <td>6.730821</td>\n",
       "      <td>3.09</td>\n",
       "      <td>40173.072174</td>\n",
       "      <td>1.505891e+06</td>\n",
       "      <td>188 Johnson Views Suite 079\\nLake Kathleen, CA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61287.067179</td>\n",
       "      <td>5.865890</td>\n",
       "      <td>8.512727</td>\n",
       "      <td>5.13</td>\n",
       "      <td>36882.159400</td>\n",
       "      <td>1.058988e+06</td>\n",
       "      <td>9127 Elizabeth Stravenue\\nDanieltown, WI 06482...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63345.240046</td>\n",
       "      <td>7.188236</td>\n",
       "      <td>5.586729</td>\n",
       "      <td>3.26</td>\n",
       "      <td>34310.242831</td>\n",
       "      <td>1.260617e+06</td>\n",
       "      <td>USS Barnett\\nFPO AP 44820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59982.197226</td>\n",
       "      <td>5.040555</td>\n",
       "      <td>7.839388</td>\n",
       "      <td>4.23</td>\n",
       "      <td>26354.109472</td>\n",
       "      <td>6.309435e+05</td>\n",
       "      <td>USNS Raymond\\nFPO AE 09386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Avg. Area Income  Avg. Area House Age  Avg. Area Number of Rooms  \\\n",
       "0      79545.458574             5.682861                   7.009188   \n",
       "1      79248.642455             6.002900                   6.730821   \n",
       "2      61287.067179             5.865890                   8.512727   \n",
       "3      63345.240046             7.188236                   5.586729   \n",
       "4      59982.197226             5.040555                   7.839388   \n",
       "\n",
       "   Avg. Area Number of Bedrooms  Area Population         Price  \\\n",
       "0                          4.09     23086.800503  1.059034e+06   \n",
       "1                          3.09     40173.072174  1.505891e+06   \n",
       "2                          5.13     36882.159400  1.058988e+06   \n",
       "3                          3.26     34310.242831  1.260617e+06   \n",
       "4                          4.23     26354.109472  6.309435e+05   \n",
       "\n",
       "                                             Address  \n",
       "0  208 Michael Ferry Apt. 674\\nLaurabury, NE 3701...  \n",
       "1  188 Johnson Views Suite 079\\nLake Kathleen, CA...  \n",
       "2  9127 Elizabeth Stravenue\\nDanieltown, WI 06482...  \n",
       "3                          USS Barnett\\nFPO AP 44820  \n",
       "4                         USNS Raymond\\nFPO AE 09386  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\M\\\\Machine_L\\\\data\\\\USA_Housing.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7fb75afb-8273-4f7d-98ba-4c5146ecc4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "# df.isnull().sum()\n",
    "# df.info()\n",
    "y = df.Price\n",
    "X = df.drop(columns = ['Price', 'Address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce4ac6c7-feb2-4470-97d5-ff9f0f63b48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코딩\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X.Address = le.fit_transform(df.Address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a08dcbf8-b57e-49ac-9fe9-9907779a9d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 데이터 split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf66f199-63c6-4913-9f03-e3b844de2141",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. \n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f06577b6-2339-4c8f-8060-aac6ef7e27bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE :  9663243422.296776\n"
     ]
    }
   ],
   "source": [
    "#5. 평가지표\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, pred)\n",
    "print('MSE : ', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e478484d-d72a-423e-8056-302768f300a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ConfusionMatrixDisplay',\n",
       " 'DetCurveDisplay',\n",
       " 'DistanceMetric',\n",
       " 'PrecisionRecallDisplay',\n",
       " 'PredictionErrorDisplay',\n",
       " 'RocCurveDisplay',\n",
       " 'SCORERS',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_base',\n",
       " '_classification',\n",
       " '_dist_metrics',\n",
       " '_pairwise_distances_reduction',\n",
       " '_pairwise_fast',\n",
       " '_plot',\n",
       " '_ranking',\n",
       " '_regression',\n",
       " '_scorer',\n",
       " 'accuracy_score',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'auc',\n",
       " 'average_precision_score',\n",
       " 'balanced_accuracy_score',\n",
       " 'brier_score_loss',\n",
       " 'calinski_harabasz_score',\n",
       " 'check_scoring',\n",
       " 'class_likelihood_ratios',\n",
       " 'classification_report',\n",
       " 'cluster',\n",
       " 'cohen_kappa_score',\n",
       " 'completeness_score',\n",
       " 'confusion_matrix',\n",
       " 'consensus_score',\n",
       " 'coverage_error',\n",
       " 'd2_absolute_error_score',\n",
       " 'd2_pinball_score',\n",
       " 'd2_tweedie_score',\n",
       " 'davies_bouldin_score',\n",
       " 'dcg_score',\n",
       " 'det_curve',\n",
       " 'euclidean_distances',\n",
       " 'explained_variance_score',\n",
       " 'f1_score',\n",
       " 'fbeta_score',\n",
       " 'fowlkes_mallows_score',\n",
       " 'get_scorer',\n",
       " 'get_scorer_names',\n",
       " 'hamming_loss',\n",
       " 'hinge_loss',\n",
       " 'homogeneity_completeness_v_measure',\n",
       " 'homogeneity_score',\n",
       " 'jaccard_score',\n",
       " 'label_ranking_average_precision_score',\n",
       " 'label_ranking_loss',\n",
       " 'log_loss',\n",
       " 'make_scorer',\n",
       " 'matthews_corrcoef',\n",
       " 'max_error',\n",
       " 'mean_absolute_error',\n",
       " 'mean_absolute_percentage_error',\n",
       " 'mean_gamma_deviance',\n",
       " 'mean_pinball_loss',\n",
       " 'mean_poisson_deviance',\n",
       " 'mean_squared_error',\n",
       " 'mean_squared_log_error',\n",
       " 'mean_tweedie_deviance',\n",
       " 'median_absolute_error',\n",
       " 'multilabel_confusion_matrix',\n",
       " 'mutual_info_score',\n",
       " 'nan_euclidean_distances',\n",
       " 'ndcg_score',\n",
       " 'normalized_mutual_info_score',\n",
       " 'pair_confusion_matrix',\n",
       " 'pairwise',\n",
       " 'pairwise_distances',\n",
       " 'pairwise_distances_argmin',\n",
       " 'pairwise_distances_argmin_min',\n",
       " 'pairwise_distances_chunked',\n",
       " 'pairwise_kernels',\n",
       " 'precision_recall_curve',\n",
       " 'precision_recall_fscore_support',\n",
       " 'precision_score',\n",
       " 'r2_score',\n",
       " 'rand_score',\n",
       " 'recall_score',\n",
       " 'roc_auc_score',\n",
       " 'roc_curve',\n",
       " 'silhouette_samples',\n",
       " 'silhouette_score',\n",
       " 'top_k_accuracy_score',\n",
       " 'v_measure_score',\n",
       " 'zero_one_loss']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "dir(sklearn.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f245057-cddc-45a4-abb2-80ddee357ecb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train_test_split in module sklearn.model_selection._split:\n",
      "\n",
      "train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)\n",
      "    Split arrays or matrices into random train and test subsets.\n",
      "    \n",
      "    Quick utility that wraps input validation,\n",
      "    ``next(ShuffleSplit().split(X, y))``, and application to input data\n",
      "    into a single call for splitting (and optionally subsampling) data into a\n",
      "    one-liner.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <cross_validation>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    *arrays : sequence of indexables with same length / shape[0]\n",
      "        Allowed inputs are lists, numpy arrays, scipy-sparse\n",
      "        matrices or pandas dataframes.\n",
      "    \n",
      "    test_size : float or int, default=None\n",
      "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "        of the dataset to include in the test split. If int, represents the\n",
      "        absolute number of test samples. If None, the value is set to the\n",
      "        complement of the train size. If ``train_size`` is also None, it will\n",
      "        be set to 0.25.\n",
      "    \n",
      "    train_size : float or int, default=None\n",
      "        If float, should be between 0.0 and 1.0 and represent the\n",
      "        proportion of the dataset to include in the train split. If\n",
      "        int, represents the absolute number of train samples. If None,\n",
      "        the value is automatically set to the complement of the test size.\n",
      "    \n",
      "    random_state : int, RandomState instance or None, default=None\n",
      "        Controls the shuffling applied to the data before applying the split.\n",
      "        Pass an int for reproducible output across multiple function calls.\n",
      "        See :term:`Glossary <random_state>`.\n",
      "    \n",
      "    shuffle : bool, default=True\n",
      "        Whether or not to shuffle the data before splitting. If shuffle=False\n",
      "        then stratify must be None.\n",
      "    \n",
      "    stratify : array-like, default=None\n",
      "        If not None, data is split in a stratified fashion, using this as\n",
      "        the class labels.\n",
      "        Read more in the :ref:`User Guide <stratification>`.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    splitting : list, length=2 * len(arrays)\n",
      "        List containing train-test split of inputs.\n",
      "    \n",
      "        .. versionadded:: 0.16\n",
      "            If the input is sparse, the output will be a\n",
      "            ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
      "            input type.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.model_selection import train_test_split\n",
      "    >>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
      "    >>> X\n",
      "    array([[0, 1],\n",
      "           [2, 3],\n",
      "           [4, 5],\n",
      "           [6, 7],\n",
      "           [8, 9]])\n",
      "    >>> list(y)\n",
      "    [0, 1, 2, 3, 4]\n",
      "    \n",
      "    >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "    ...     X, y, test_size=0.33, random_state=42)\n",
      "    ...\n",
      "    >>> X_train\n",
      "    array([[4, 5],\n",
      "           [0, 1],\n",
      "           [6, 7]])\n",
      "    >>> y_train\n",
      "    [2, 0, 3]\n",
      "    >>> X_test\n",
      "    array([[2, 3],\n",
      "           [8, 9]])\n",
      "    >>> y_test\n",
      "    [1, 4]\n",
      "    \n",
      "    >>> train_test_split(y, shuffle=False)\n",
      "    [[0, 1, 2], [3, 4]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b56872-3c03-4cd9-a5c6-c3a0ea7531c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
